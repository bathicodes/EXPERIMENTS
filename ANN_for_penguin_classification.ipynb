{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN for penguin classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXc8HFTP5WrNDSmr5NuIap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bathicodes/EXPERIMENTS/blob/main/ANN_for_penguin_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains all the necessary steps to build a ANN based penguin classification model. Dataset can be found on data professor's GitHub page. Visit this [link](https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv) for grab the raw dataset. EDA for this dataset can find [here](https://github.com/bathicodes/EXPERIMENTS/blob/main/EDA_Penguins.ipynb)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YUoVfLBOaQbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "8ksZqmrtem-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "TEezB3LNaEGo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "n9eCKEA9gs0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv')\n",
        "x = dataset.drop('species', axis=1)\n",
        "y = dataset['species']"
      ],
      "metadata": {
        "id": "5vrAbsmOguwh"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJAWALfIhGuK",
        "outputId": "ae365845-0cd3-461e-b258-20545c593f2e"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Torgersen', 39.1, 18.7, 181, 3750, 'male'],\n",
              "       ['Torgersen', 39.5, 17.4, 186, 3800, 'female'],\n",
              "       ['Torgersen', 40.3, 18.0, 195, 3250, 'female'],\n",
              "       ...,\n",
              "       ['Dream', 49.6, 18.2, 193, 3775, 'male'],\n",
              "       ['Dream', 50.8, 19.0, 210, 4100, 'male'],\n",
              "       ['Dream', 50.2, 18.7, 198, 3775, 'female']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-rq2RNehJJA",
        "outputId": "17c69010-f0ac-4053-89e3-1a716c2415b6"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
              "       'Adelie', 'Adelie', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Gentoo', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
              "       'Chinstrap', 'Chinstrap', 'Chinstrap', 'Chinstrap'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ],
      "metadata": {
        "id": "_eMtdUPTi13Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding categorical data columns using OneHotEncoder"
      ],
      "metadata": {
        "id": "l5vrgl-vi4FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "eFirqeF4i-PD"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNuaApZbjfDL",
        "outputId": "c2825f0b-4903-448f-dd23-5d8b8919ef41"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 ... 181 3750 'male']\n",
            " [0.0 0.0 1.0 ... 186 3800 'female']\n",
            " [0.0 0.0 1.0 ... 195 3250 'female']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... 193 3775 'male']\n",
            " [0.0 1.0 0.0 ... 210 4100 'male']\n",
            " [0.0 1.0 0.0 ... 198 3775 'female']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoding for Gender using LabelEncoder"
      ],
      "metadata": {
        "id": "Ey8J0D0kyajW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "x[:,7] = le.fit_transform(x[:,7])"
      ],
      "metadata": {
        "id": "jlkZ-Eucyg27"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3vG-L-B0E_H",
        "outputId": "8a0c259b-caf0-4421-a74e-a7159d2725e2"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 ... 181 3750 1]\n",
            " [0.0 0.0 1.0 ... 186 3800 0]\n",
            " [0.0 0.0 1.0 ... 195 3250 0]\n",
            " ...\n",
            " [0.0 1.0 0.0 ... 193 3775 1]\n",
            " [0.0 1.0 0.0 ... 210 4100 1]\n",
            " [0.0 1.0 0.0 ... 198 3775 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Y with LabelEncoder"
      ],
      "metadata": {
        "id": "b5wNK301DIcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "zd8XcTN2DOpN"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting dataset as training and testing set"
      ],
      "metadata": {
        "id": "zWdOpZwp1-wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "x_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "Uig7CCRR2EUa"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature scaling"
      ],
      "metadata": {
        "id": "vRrx4ZXy2UAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "wrsCR49v2WGH"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating artificial Neural Network model architecture"
      ],
      "metadata": {
        "id": "K0U7SB2eADfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a sequential method"
      ],
      "metadata": {
        "id": "fD42QQvdAQ_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "fzGnpFyOALiJ"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding first hidden layer"
      ],
      "metadata": {
        "id": "XcjhlWtNAUzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "LSwwpDhIAZ0_"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding second hidden layer"
      ],
      "metadata": {
        "id": "Eod6af_WAmkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "CfXIGrakApk9"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding output layer"
      ],
      "metadata": {
        "id": "DkQe3KlrAtlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"
      ],
      "metadata": {
        "id": "BOrj1VQmAyK1"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling model"
      ],
      "metadata": {
        "id": "fefrCNfRA6g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HZBkEMaRA9or"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model on training data"
      ],
      "metadata": {
        "id": "yNW_HbM_BHo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('penguin.h5', monitor='loss', verbose=1, save_best_only=True)\n",
        "\n",
        "history = ann.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaYm71INBL4Z",
        "outputId": "94851c60-2a81-472a-a831-710320b262fe"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 1: loss improved from inf to 0.02625, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 2: loss improved from 0.02625 to 0.02568, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 3: loss improved from 0.02568 to 0.02505, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 4: loss improved from 0.02505 to 0.02446, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 5: loss improved from 0.02446 to 0.02392, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 6: loss improved from 0.02392 to 0.02345, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 7: loss improved from 0.02345 to 0.02296, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 8: loss improved from 0.02296 to 0.02246, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0517 - accuracy: 1.0000\n",
            "Epoch 9: loss improved from 0.02246 to 0.02193, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 10: loss improved from 0.02193 to 0.02152, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 11: loss improved from 0.02152 to 0.02101, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 12: loss improved from 0.02101 to 0.02064, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 13: loss improved from 0.02064 to 0.02018, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 14: loss improved from 0.02018 to 0.01979, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 15: loss improved from 0.01979 to 0.01941, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0347 - accuracy: 1.0000\n",
            "Epoch 16: loss improved from 0.01941 to 0.01909, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 17: loss improved from 0.01909 to 0.01872, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 18: loss improved from 0.01872 to 0.01833, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 19: loss improved from 0.01833 to 0.01800, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 20: loss improved from 0.01800 to 0.01765, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 21: loss improved from 0.01765 to 0.01733, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 22: loss improved from 0.01733 to 0.01707, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 23: loss improved from 0.01707 to 0.01676, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 24: loss improved from 0.01676 to 0.01645, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 25: loss improved from 0.01645 to 0.01612, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 26: loss improved from 0.01612 to 0.01589, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 27: loss improved from 0.01589 to 0.01561, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 28: loss improved from 0.01561 to 0.01538, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 29: loss improved from 0.01538 to 0.01502, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 30: loss improved from 0.01502 to 0.01480, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 31: loss improved from 0.01480 to 0.01455, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 32: loss improved from 0.01455 to 0.01443, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 33: loss improved from 0.01443 to 0.01409, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 34: loss improved from 0.01409 to 0.01389, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 35: loss improved from 0.01389 to 0.01370, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 36: loss improved from 0.01370 to 0.01348, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 37: loss improved from 0.01348 to 0.01320, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 38: loss improved from 0.01320 to 0.01300, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 39: loss improved from 0.01300 to 0.01283, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 40: loss improved from 0.01283 to 0.01272, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 41: loss improved from 0.01272 to 0.01250, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 42: loss improved from 0.01250 to 0.01229, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 43: loss improved from 0.01229 to 0.01206, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 44: loss improved from 0.01206 to 0.01194, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 45: loss improved from 0.01194 to 0.01176, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 46: loss improved from 0.01176 to 0.01160, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 47: loss improved from 0.01160 to 0.01141, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 48: loss improved from 0.01141 to 0.01136, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 49: loss improved from 0.01136 to 0.01116, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 50: loss improved from 0.01116 to 0.01093, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 51: loss improved from 0.01093 to 0.01078, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 52: loss improved from 0.01078 to 0.01070, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 53: loss improved from 0.01070 to 0.01053, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 54: loss improved from 0.01053 to 0.01034, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 55: loss improved from 0.01034 to 0.01022, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 56: loss improved from 0.01022 to 0.01010, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 57: loss improved from 0.01010 to 0.00996, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 58: loss improved from 0.00996 to 0.00982, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 59: loss improved from 0.00982 to 0.00968, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 60: loss improved from 0.00968 to 0.00958, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 61: loss improved from 0.00958 to 0.00944, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 62: loss improved from 0.00944 to 0.00936, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 63: loss improved from 0.00936 to 0.00921, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 64: loss improved from 0.00921 to 0.00910, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 65: loss improved from 0.00910 to 0.00898, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 66: loss improved from 0.00898 to 0.00888, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 67: loss improved from 0.00888 to 0.00875, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 68: loss improved from 0.00875 to 0.00871, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 69: loss improved from 0.00871 to 0.00855, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 70: loss improved from 0.00855 to 0.00845, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 71: loss improved from 0.00845 to 0.00838, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 72: loss improved from 0.00838 to 0.00824, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 73: loss improved from 0.00824 to 0.00815, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 74: loss improved from 0.00815 to 0.00805, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 75: loss improved from 0.00805 to 0.00795, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 76: loss improved from 0.00795 to 0.00788, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 77: loss improved from 0.00788 to 0.00776, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 78: loss improved from 0.00776 to 0.00771, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 79: loss improved from 0.00771 to 0.00760, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 80: loss improved from 0.00760 to 0.00752, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 81: loss improved from 0.00752 to 0.00741, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 82: loss improved from 0.00741 to 0.00734, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 83: loss improved from 0.00734 to 0.00729, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 84: loss improved from 0.00729 to 0.00726, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 85: loss improved from 0.00726 to 0.00711, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 86: loss improved from 0.00711 to 0.00704, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 87: loss improved from 0.00704 to 0.00694, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 88: loss improved from 0.00694 to 0.00690, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 89: loss improved from 0.00690 to 0.00679, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 90: loss improved from 0.00679 to 0.00673, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 91: loss improved from 0.00673 to 0.00667, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 92: loss improved from 0.00667 to 0.00659, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 93: loss improved from 0.00659 to 0.00653, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 94: loss improved from 0.00653 to 0.00646, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 95: loss improved from 0.00646 to 0.00638, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 96: loss improved from 0.00638 to 0.00629, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 97: loss improved from 0.00629 to 0.00628, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 98: loss improved from 0.00628 to 0.00616, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 99: loss improved from 0.00616 to 0.00611, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 100: loss improved from 0.00611 to 0.00604, saving model to penguin.h5\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Histograms"
      ],
      "metadata": {
        "id": "-e3HgNsbGGOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ann.history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNya0ImKZGm",
        "outputId": "2021319e-937b-45a4-b7d8-a68096344979"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "accuracy = history.history['accuracy']\n",
        "plt.plot(loss_train, 'g', label='Training loss')\n",
        "plt.plot(accuracy, 'b', label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hzh1hvF5GIzp",
        "outputId": "791be167-a895-411b-f8da-0a0a4b2bd617"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation test set"
      ],
      "metadata": {
        "id": "fIrR2gKhDXMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(x_test)\n",
        "new_y = []\n",
        "for i in y_pred:\n",
        "  new_y_pred = np.argmax(i)\n",
        "  new_y.append(new_y_pred)\n",
        "\n",
        "y_pred_value = np.array(new_y)\n",
        "\n",
        "print(np.concatenate((y_test.reshape(len(y_test),1),y_pred_value.reshape(len(y_pred_value),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUPY09fBDebj",
        "outputId": "c13772ed-a2c7-4eed-ece3-257f9a7ffa2e"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making confusion matrix and accuracy score"
      ],
      "metadata": {
        "id": "xRnFJdz1FecX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_value)\n",
        "print(cm)\n",
        "ac = accuracy_score(y_test, y_pred_value)\n",
        "print(ac)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw8nGdB9FkMl",
        "outputId": "36850c98-8e63-4c36-e67f-d3dba455deed"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[39  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 18]]\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}